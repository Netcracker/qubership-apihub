# Qubership APIHUB Installation on local k8s cluster

This guide is for development purposes mainly.
It describes how to set up local k8s cluster and use it for APIHUB deployment.

This can be helpful for development cases. It is not a production ready deployment schema.

- [How to set up k8s cluster on your PC](#how-to-set-up-k8s-cluster-on-your-pc)
  * [Kind](#kind)
    + [Prerequisites](#prerequisites)
    + [Installing](#installing)
    + [Uninstalling](#uninstalling)
  * [Rancher Desktop](#rancher-desktop)
    + [Installing](#installing-1)
    + [Ingress Controller](#ingress-controller)
- [APIHUB installation via Helm](#apihub-installation-via-helm)
  * [Deployment via single script](#deployment-via-single-script)
  * [Verify Installation](#verify-installation)
  * [Uninstallation](#uninstallation)
  * [Script for setting up everything](#script-for-setting-up-everything)
  * [Deploy several APIHUBs simultaneously](#deploy-several-apihubs-simultaneously)

# How to set up k8s cluster on your PC

Two possible tools described below. In general there are a lot more options how to run k8s locally. You can use any k8s distribution on your choice.

## Kind

Official site: https://kind.sigs.k8s.io/docs/user/quick-start/

### Prerequisites

1. Install podman and set it up
2. Install kubectl
3. Install OpenLENS for managing the cluster (Optional)

### Installing 

Download and install corresponding binary from https://github.com/kubernetes-sigs/kind/releases

Start the cluster by the following command (bash/Power Shell)

```
cat <<EOF | kind create cluster --config=-
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  extraPortMappings:
  - containerPort: 80
    hostPort: 80
    protocol: TCP
  - containerPort: 443
    hostPort: 443
    protocol: TCP
EOF
```

```
@"
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  extraPortMappings:
  - containerPort: 80
    hostPort: 80
    protocol: TCP
  - containerPort: 443
    hostPort: 443
    protocol: TCP
"@ | kind create cluster --config=-
```

Install Ingress Controller `kubectl apply -f https://kind.sigs.k8s.io/examples/ingress/deploy-ingress-nginx.yaml`

### Uninstalling 

```
kind delete cluster
```

### Tricks

Nginx Ingress Controller may work unstable on WSL/Podman. Solution taken from https://github.com/kubernetes/ingress-nginx/issues/10765

1. Go to Podman machine terminal
1. Edit `/usr/share/containers/containers.conf`. Find line `#pids_limit = 2048` and chage to `pids_limit = -1`
1. Restart Podman machine

## Rancher Desktop

[Rancher Desktop Official Site](https://rancherdesktop.io/)

### Installing

1. Install Rancher Desktop:   
   Official Installation Guide(https://docs.rancherdesktop.io/getting-started/installation)
1. Start Kubernetes cluster in Rancher Desktop

### Ingress Controller

Default ports used:
- 80 (HTTP)
- 443 (HTTPS)

If ports are busy:
-  Change ports in Rancher Desktop settings, OR
-  Use port forwarding


# APIHUB installation via Helm

No manual action required, special `local-k8s-values.yaml` prefilled with values which fits for deployment in local k8s cluster. Secrets values which can't be prefilled are generated by scripts.

Please also refer to official [Installation Notes](/docs/installation-guide.md)

## Deployment via single script 

```
    cd qubership-apihub/helm-templates/qubership-apihub

    # Generate JWT key
    generate_jwt_pkey.sh

    # Generate passwords
    generate-local-passwords.sh
    
    # Deploy PostgreSQL Database
    helm install postgres-db -n postgres-db --create-namespace ../postgres-db

    # Deploy APIHIB Application
    helm install apihub -n apihub --create-namespace -f ../qubership-apihub/local-k8s-values.yaml -f ../qubership-apihub/local-secrets.yaml ../qubership-apihub
```

## Verify Installation
Check running pods: `kubectl get pods -n apihub`

Expected output:

```
     NAMESPACE       NAME                                                    READY   STATUS    RESTARTS       AGE
     apihub          qubership-apihub-backend-866965f5cc-lxv9l               1/1     Running   0              3m
     apihub          qubership-apihub-build-task-consumer-588bf5d685-bkjjm   1/1     Running   0              3m
     apihub          qubership-apihub-ui-99d98758b-sh5tk                     1/1     Running   0              3m
```

Qubership APIHUB will be accessible on [https://qubership-apihub.localhost/login](https://qubership-apihub.localhost/login)

Credentials for login can be found in `/helm-templates/qubership-apihub/local-secrets.yaml` file


## Uninstallation

```
    helm uninstall apihub -n apihub
    helm uninstall postgres-db -n postgres-db
```

## Script for setting up everything

```
cat <<EOF | kind create cluster --config=-
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  extraPortMappings:
  - containerPort: 80
    hostPort: 80
    protocol: TCP
  - containerPort: 443
    hostPort: 443
    protocol: TCP
EOF

kubectl apply -f https://kind.sigs.k8s.io/examples/ingress/deploy-ingress-nginx.yaml
./generate_jwt_pkey.sh
./generate-local-passwords.sh
sleep 30
helm install postgres-db -n postgres-db --create-namespace ../postgres-db
sleep 30
helm install apihub -n apihub --create-namespace -f ../qubership-apihub/local-k8s-values.yaml -f ../qubership-apihub/local-secrets.yaml ../qubership-apihub
sleep 30
echo "######"
echo "APIHUB is accesible by https://qubership-apihub.localhost/login"
cat local-secrets.yaml | grep -E 'adminEmail|adminPassword|accessToken'
echo "######"
```

## Deploy several APIHUBs simultaneously

**Prerequisites:**

You already have k8s with Postgres and APIHUB in it.

**Deployment:**

Basically there are to options:

1. Deploy separate Postgres for second APIHUB
2. Create separate logical database in existing Postgres

Option 2 simpler from execution perspective and cheaper from HW perspective so the following steps is for option 2

**Step 1 - Create new logical database in Postgres cluster**

Option 1:

Execute the following command in `pg-common-0` POD in `postgres-db` namespace. Either via kubectl or OpenLens

```
psql -U apihub_backend_user -d postgres -c "CREATE USER apihub_backend_user_2 WITH PASSWORD 'apihub_backend_password_2' CREATEDB INHERIT;" -c "CREATE DATABASE apihub_backend_2 OWNER apihub_backend_user_2;" -c "GRANT ALL PRIVILEGES ON DATABASE apihub_backend_2 TO apihub_backend_user_2;"
```

*Hint:* Postgres admin credentials are: `apihub_backend_user/apihub_backend_password`

Option 2:

Do port forward for `pg-common` service in `postgres-db` namespace. Either via kubectl or OpenLens.

Connect to PG via pgAdmin and execute the following SQL:

```
      CREATE USER apihub_backend_user_2 WITH PASSWORD 'apihub_backend_password_2' CREATEDB INHERIT;
      CREATE DATABASE apihub_backend_2 OWNER apihub_backend_user_2;
      GRANT ALL PRIVILEGES ON DATABASE apihub_backend_2 TO apihub_backend_user_2;
```

Or you can do the same (create user, create db) via pgAdmin UI.

**Step 2 - prepare helm chart**

Copy directory `qubership-apihub` with name `qubership-apihub-2`.

Modify the following lines in `local-k8s-values.yaml`:

```
apihubUrl: 'qubership-apihub-2.localhost' 
...
      dbName: 'apihub_backend_2' 
      dbUsername: 'apihub_backend_user_2'  
      dbPassword: 'apihub_backend_password_2' 
```

Run the following commands to generate secrets:

```
./qubership-apihub-2/generate_jwt_pkey.sh
./qubership-apihub-2/generate-local-passwords.sh
```

In order to change APIHUB release modify `tag: 'dev'` for services to desired docker images tags.

**Step 3 - execute deploy**

Run the following command:

```
helm install apihub -n apihub-2 --create-namespace -f ./qubership-apihub-2/local-k8s-values.yaml -f ../qubership-apihub-2/local-secrets.yaml ./qubership-apihub-2
```

**Done**

New APIHUB is acessible via `http://qubership-apihub-2.localhost`
