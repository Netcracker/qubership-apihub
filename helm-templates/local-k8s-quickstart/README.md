# Qubership APIHUB quickstart installation on local k8s cluster

This folder contains a set of guides, helm charts, templates and scripts for quick setting up of k8s cluster on your PC and deploying APIHUB into it.

This can be helpful for development and RnD use cases. 

It is not a production ready deployment schema.

- [How to set up k8s cluster on your PC](#how-to-set-up-k8s-cluster-on-your-pc)
  * [Kind](#kind)
    + [Prerequisites](#prerequisites)
    + [Installing](#installing)
    + [Uninstalling](#uninstalling)
  * [Rancher Desktop](#rancher-desktop)
    + [Installing](#installing-1)
    + [Ingress Controller](#ingress-controller)
- [APIHUB installation via Helm](#apihub-installation-via-helm)
  * [Prerequisites](#prerequisites-1)
  * [Deployment](#deployment)
  * [Verify Installation](#verify-installation)
  * [Uninstallation](#uninstallation)
  * [Deploy several APIHUBs simultaneously](#deploy-several-apihubs-simultaneously)
  
# Quickstart

1. Install the following tools: podman, kind, kubectl, helm
2. Run `apihub-quickstart.sh`
3. APIHUB is on http://qubership-apihub.localtest.me/login

# How to set up k8s cluster on your PC

Two possible tools described below. In general there are a lot more options how to run k8s locally. You can use any k8s distribution on your choice.

## Kind

Official site: https://kind.sigs.k8s.io/docs/user/quick-start/

### Prerequisites

1. Install podman and set it up
2. Install kubectl
3. Install OpenLENS for managing the cluster (Optional)

### Installing 

Download and install corresponding binary from https://github.com/kubernetes-sigs/kind/releases

Start the cluster by the following command (bash/Power Shell)

```
cat <<EOF | kind create cluster --config=-
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  extraPortMappings:
  - containerPort: 80
    hostPort: 80
    protocol: TCP
  - containerPort: 443
    hostPort: 443
    protocol: TCP
EOF
```

```
@"
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  extraPortMappings:
  - containerPort: 80
    hostPort: 80
    protocol: TCP
  - containerPort: 443
    hostPort: 443
    protocol: TCP
"@ | kind create cluster --config=-
```

**Install Ingress Controller** `kubectl apply -f https://kind.sigs.k8s.io/examples/ingress/deploy-ingress-nginx.yaml`

### Uninstalling 

```
kind delete cluster
```

### Tricks

Nginx Ingress Controller may work unstable on WSL/Podman. Solution taken from https://github.com/kubernetes/ingress-nginx/issues/10765

1. Go to Podman machine terminal
1. Edit `/usr/share/containers/containers.conf`. Find line `#pids_limit = 2048` and chage to `pids_limit = -1`
1. Restart Podman machine

## Rancher Desktop

[Rancher Desktop Official Site](https://rancherdesktop.io/)

### Installing

1. Install Rancher Desktop:   
   Official Installation Guide(https://docs.rancherdesktop.io/getting-started/installation)
1. Start Kubernetes cluster in Rancher Desktop

### Ingress Controller

Default ports used:
- 80 (HTTP)
- 443 (HTTPS)

If ports are busy:
-  Change ports in Rancher Desktop settings, OR
-  Use port forwarding


# APIHUB installation via Helm

Quickstart procedure uses official Qubership APIHUB [Helm Chart](../qubership-apihub/). Please also refer to official [Installation Notes](/docs/installation-guide.md).

This folder contains `postgresql` and `keycloack` Helm charts for Qubserhip APIHUB dependecies deployment.

`qubership-apihub` folder contains prefilled `values.yaml` files with parameters values fits for deployment to local k8s cluster - so no need to care about filling values. Required secrets are generated by scripts.

## Prerequisites

1. Helm
2. Bash (GitBash, Cygwin, etc)


## Deployment

Deployment phases represented by scripts in `scripts` folder, so you can see what happens on each step in them:

- `1-start-kind-cluster.sh`
- `2-deploy-postgres.sh`
- `3-generate-secrets.sh`
- `4-deploy-keycloack.sh` (optional, need for `5-deploy-apihub-with-keycloack`)
- `5-deploy-apihub.sh`
- `5-deploy-apihub-with-keycloack.sh`
- `6-patch-apihub-hosts.sh` (required for keycloak setup)

One-liners:

1. `apihub-quickstart.sh` - PostgreSQL + Pure APIHUB. Basic option
1. `apihub-with-keycloack-quickstart.sh` - APIHUB with SAML and OIDC integration via Keycloak


## Verify Installation
Check running pods: `kubectl get pods -n apihub`

Expected output:

```
     NAMESPACE       NAME                                                    READY   STATUS    RESTARTS       AGE
     apihub          qubership-apihub-backend-866965f5cc-lxv9l               1/1     Running   0              3m
     apihub          qubership-apihub-build-task-consumer-588bf5d685-bkjjm   1/1     Running   0              3m
     apihub          qubership-apihub-ui-99d98758b-sh5tk                     1/1     Running   0              3m
```

Qubership APIHUB will be accessible on [https://qubership-apihub.localtest.me](https://qubership-apihub.localtest.me)

Credentials for login can be found in `./qubership-apihub/local-secrets.yaml` file


## Uninstallation

```
    helm uninstall apihub -n apihub
    helm uninstall postgres-db -n postgres-db
```

## Deploy several APIHUBs simultaneously

**Prerequisites:**

You already have k8s with Postgres and APIHUB in it.

**Deployment:**

Basically there are to options:

1. Deploy separate Postgres for second APIHUB
2. Create separate logical database in existing Postgres

Option 2 simpler from execution perspective and cheaper from HW perspective so the following steps is for option 2

**Step 1 - Create new logical database in Postgres cluster**

Option 1:

Execute the following command in `pg-common-0` POD in `postgres-db` namespace. Either via kubectl or OpenLens

```
psql -U apihub_backend_user -d postgres -c "CREATE USER apihub_backend_user_2 WITH PASSWORD 'apihub_backend_password_2' CREATEDB INHERIT;" -c "CREATE DATABASE apihub_backend_2 OWNER apihub_backend_user_2;" -c "GRANT ALL PRIVILEGES ON DATABASE apihub_backend_2 TO apihub_backend_user_2;"
```

*Hint:* Postgres admin credentials are: `postgres/postgres`

Option 2:

Do port forward for `pg-common` service in `postgres-db` namespace. Either via kubectl or OpenLens.

Connect to PG via pgAdmin and execute the following SQL:

```
      CREATE USER apihub_backend_user_2 WITH PASSWORD 'apihub_backend_password_2' CREATEDB INHERIT;
      CREATE DATABASE apihub_backend_2 OWNER apihub_backend_user_2;
      GRANT ALL PRIVILEGES ON DATABASE apihub_backend_2 TO apihub_backend_user_2;
```

Or you can do the same (create user, create db) via pgAdmin UI.

**Step 2 - prepare helm chart**

Copy directory `qubership-apihub` with name `qubership-apihub-2`.

Modify the following lines in `local-k8s-values.yaml`:

```
apihubUrl: 'qubership-apihub-2.localtest.me' 
...
      dbName: 'apihub_backend_2' 
      dbUsername: 'apihub_backend_user_2'  
      dbPassword: 'apihub_backend_password_2' 
```
In order to change APIHUB release modify `tag: 'dev'` for services to desired docker images tags.

**Step 3 - execute deploy**

Run the following command:

```
helm install apihub -n apihub-2 --create-namespace -f ../qubership-apihub-2/local-k8s-values.yaml -f ../qubership-apihub-2/local-secrets.yaml ../../qubership-apihub
```

**Done**

New APIHUB is acessible via `https://qubership-apihub-2.localtest.me`
